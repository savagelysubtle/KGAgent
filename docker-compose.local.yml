# ============================================================================
# KG Agent - Complete Local Deployment
# ============================================================================
# This docker-compose file runs the entire KG Agent stack locally.
#
# Usage:
#   docker compose -f docker-compose.local.yml up -d
#
# Requirements:
#   - Docker Desktop with at least 8GB RAM allocated
#   - LM Studio running on host machine (port 1234) for LLM features
#     OR use environment variable to point to another LLM service
#
# Services:
#   - api:        FastAPI backend (port 8000)
#   - dashboard:  Next.js frontend (port 3000)
#   - falkordb:   Graph database (port 6380)
#   - redis:      Message broker/cache (port 6379)
#   - worker:     Celery background tasks
# ============================================================================

services:
  # ===========================================================================
  # FalkorDB - Graph Database with Vector Search
  # ===========================================================================
  falkordb:
    image: falkordb/falkordb:edge
    container_name: kg-falkordb
    hostname: falkordb
    restart: unless-stopped
    ports:
      - "${FALKORDB_PORT:-6380}:6379"
    environment:
      - FALKORDB_ARGS=--requirepass ${FALKORDB_PASSWORD:-kgagent123}
    volumes:
      - falkordb_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${FALKORDB_PASSWORD:-kgagent123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - kg-network

  # ===========================================================================
  # Redis - Message Broker & Cache
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: kg-redis
    hostname: redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - kg-network

  # ===========================================================================
  # FastAPI Backend
  # ===========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: kg-api
    hostname: api
    restart: unless-stopped
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      # Application
      - APP_ENV=production
      - DEBUG=false
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Redis/Celery
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # FalkorDB - Use Docker service name
      - GRAPH_DRIVER=falkordb
      - FALKORDB_HOST=falkordb
      - FALKORDB_PORT=6379
      - FALKORDB_PASSWORD=${FALKORDB_PASSWORD:-kgagent123}
      # ChromaDB (embedded)
      - CHROMA_PERSIST_DIR=/app/data/chroma_db
      - CHROMA_COLLECTION_NAME=document_chunks
      # Storage
      - STORAGE_DIR=/app/storage
      - DOCUMENTS_DB_PATH=/app/storage/documents.db
      # Models
      - HF_HOME=/app/models/embeddings
      - HF_EMBEDDING_MODEL=${HF_EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      # LLM - Point to host machine's LM Studio
      # host.docker.internal resolves to the host machine from inside containers
      - LLM_BASE_URL=${LLM_BASE_URL:-http://host.docker.internal:1234/v1}
      - LLM_API_KEY=${LLM_API_KEY:-lm-studio}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-local-model}
      # CORS - Allow dashboard
      - CORS_ORIGINS=["http://localhost:3000","http://dashboard:3000","http://localhost:8000"]
    depends_on:
      falkordb:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      # Persist data between container restarts
      - ./storage:/app/storage
      - ./data:/app/data
      - ./models:/app/models
      - ./cache:/app/cache
      - ./logs:/app/logs
    networks:
      - kg-network
    # Allow container to access host network (for LM Studio)
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # ===========================================================================
  # Celery Worker - Background Task Processing
  # ===========================================================================
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: kg-worker
    hostname: worker
    restart: unless-stopped
    environment:
      - APP_ENV=production
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Redis/Celery
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # FalkorDB
      - GRAPH_DRIVER=falkordb
      - FALKORDB_HOST=falkordb
      - FALKORDB_PORT=6379
      - FALKORDB_PASSWORD=${FALKORDB_PASSWORD:-kgagent123}
      # ChromaDB
      - CHROMA_PERSIST_DIR=/app/data/chroma_db
      # Storage
      - STORAGE_DIR=/app/storage
      - DOCUMENTS_DB_PATH=/app/storage/documents.db
      # Models
      - HF_HOME=/app/models/embeddings
      # LLM
      - LLM_BASE_URL=${LLM_BASE_URL:-http://host.docker.internal:1234/v1}
      - LLM_API_KEY=${LLM_API_KEY:-lm-studio}
    depends_on:
      falkordb:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./storage:/app/storage
      - ./data:/app/data
      - ./models:/app/models
      - ./cache:/app/cache
      - ./logs:/app/logs
    command: celery -A src.kg_agent.tasks.celery_app worker --loglevel=info --concurrency=2
    networks:
      - kg-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # ===========================================================================
  # Next.js Dashboard
  # ===========================================================================
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
      args:
        # Use Docker service name for API URL during build
        NEXT_PUBLIC_API_URL: http://localhost:8000
    container_name: kg-dashboard
    hostname: dashboard
    restart: unless-stopped
    ports:
      - "${DASHBOARD_PORT:-3000}:3000"
    environment:
      - NODE_ENV=production
      # Runtime API URL - points to host's exposed port
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      # LLM for CopilotKit (if used)
      - LLM_BASE_URL=${LLM_BASE_URL:-http://host.docker.internal:1234/v1}
      - LLM_API_KEY=${LLM_API_KEY:-lm-studio}
    depends_on:
      - api
    networks:
      - kg-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

# =============================================================================
# Networks
# =============================================================================
networks:
  kg-network:
    driver: bridge
    name: kg-agent-network

# =============================================================================
# Volumes
# =============================================================================
volumes:
  falkordb_data:
    name: kg-agent-falkordb-data
  redis_data:
    name: kg-agent-redis-data

